---
slug: whos-pulling-the-strings-ai-season
title: Who's Really Pulling the Strings in the Season of AI?
authors: [tim]
tags: [ai, llm, development, productivity, context, agent-mode, vibe-coding]
---

Who's really pulling the strings in the season of AI?

## The Season of AI

They're saying it's the season of AI. Big voices in tech declare that within three months, six, twelve, AI will be writing all the code, automating the work, replacing developers at the keyboard.

Me? I'm not so sure.

<!-- truncate -->

## Living with AI

Don't get me wrong. I'm all in on AI. I've been living with it for a while now. Check my profile and you'll see I was taking prompt engineering courses back when most people were still asking what a prompt even was. I've been using AI tools daily, not as a gimmick but as a genuine extension of my work. This doesn't make me special, but what does seem to separate me from a lot of the "vibe" coders is that I've spent years building and shipping production-quality code that drives revenue.

## The Trade-offs

And for me? Well, AI's taken away a lot of the drudgery. The tedious tasks, the old repetitive jobs are largely gone. But here's the thing no one tells you: what it gives with one hand, it takes with another. Every shortcut I've gained, I've paid for in time. Time spent experimenting, learning, refining. I've consumed miles of blog posts, hours of video, written rules, trained LoRAs, designed prompt templates, even built my own agentic AI-fuelled task management tools just to keep pace.

Has it made me more productive? Absolutely. But it didn't happen by magic. And if you took me out of the seat, the AI wouldn't keep humming along on its own.

## The Context Window

I am the context window. I'm the one holding the shape of the work, making the calls, knowing when to trust and when to intervene.

So, when people ask if AI's coming for our jobs? I think maybe it's not about replacing us. Maybe it's about changing what the job is.

## Adapting to Change

What some outside the world of hands-on development might not realise is that development is always evolving. Tools come, tools go. We adapt. That's the job.

And in this season of AI? You'd better know who's pulling the strings.

## Upping Your AI Coding Game

If you're looking to ride this frontier effectively, don't just strap on your AI sidekick and hope for the best. There's strategy to becoming the trail boss in this new territory.

### Become the Context Wrangler

As we explored in ["I'm Your Huckleberry - Managing the LLM Context Frontier"](/blog/im-your-huckleberry-context), the most valuable skill you can develop is context management. LLMs aren't psychic gunslingers, they're storytellers working with what's in their campfire circle. Learn to feed them the right context at the right time, and use tools like Huckleberry that help "keep the important bits close to the fire." Remember: you're not just coding anymore; you're curating the inputs that shape what comes out.

### Tame That Vibe Coding

Falling for the "vibe coding" trap is easier than tumbling off a horse. As outlined in ["Taming Vibe Coding"](/blog/taming-vibe-coding), we need to establish a robust posse of tools to keep AI output in check. TypeScript becomes your sheriff's badge, ESLint your deputy, and your test suite the jail that holds hallucinations prisoner. Follow our "trail-guide for safer AI sessions", prompt narrow, anchor with real types, scaffold then refactor, write tests first, and let CI stand guard.

### Scale Beyond the Solo Ride

Individual productivity is just the beginning. ["Scale Up Your Codebase, Cowboy"](/blog/scale-up-your-codebase) showed how Huckleberry can transform Copilot Chat into a project manager that carves requirements into bite-sized tasks. When you're ready to graduate from lone ranger to trail boss, you need systems that scale. Try techniques like "Write the spec first, ride later" and linking tasks back to requirements to maintain coherence as complexity grows.

### Extend Your Reach with Copilot's Web Fetching

Don't forget that modern AI tools can be your research deputies too. In ["GitHub Copilot Rides into Town"](/blog/github-copilot-fetching), we detailed how the `#fetch` command turns your sidekick into a documentation hunter. Use pinpoint queries to specific documentation pages, blend with workspace snippets, and always "tilt your hat towards the source before pushing code to production."

### Track, Measure, Improve

Start tracking where AI actually saves you time versus where it's creating new work. Are you spending more time reviewing and fixing hallucinations than you would have spent just writing the code? Or has it unlocked new capabilities you wouldn't have attempted otherwise? The data might surprise you, and help you refine where to deploy your AI sidekick most effectively.

## Final Thoughts

In this season of AI, the winners won't be those with the fanciest models or the longest context windows. The real advantage goes to those who understand the dance between human and machine, when to lead, when to follow, and when to change partners entirely.

Because at the end of the day, someone's pulling the strings. Make sure it's you.

## FAQs

### Q: What's the most important skill for working effectively with AI coding tools?

A: Context management, understanding how to provide the right information at the right time, keeping the AI focused on what matters, and recognizing when it's drifted off course.

### Q: How can I avoid getting caught in "vibe coding" traps?

A: Implement strong guardrails through TypeScript, comprehensive testing, and code review processes. Prompt for smaller, more focused outputs and always verify generated code against your actual requirements.

### Q: How do I balance learning AI tools with actual development work?

A: Start small with focused use cases where AI clearly saves time, gradually expand as you become comfortable, and set aside dedicated time for experimenting with new AI capabilities outside critical path work.
